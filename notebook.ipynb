{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scripts are written for Python 3.9.6\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "## please also:\n",
    "'''\n",
    "1. Change the Request-Header main/src/hys_portal_scraper.py#L27 to your own E-Mail Address\n",
    "2. Make sure you set a wait-time above 10 sec\n",
    "3. Create a MySQL-Database and specify its configs in: main/src/database/database_connection.py\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from src.hys_portal_scraper import Portal_Scraper\n",
    "from src.scrapers.initiative_scraper import Initiative_Scraper\n",
    "from src.scrapers.feedback_scraper import Feedback_Scraper\n",
    "from src.scrapers.attachment_scraper import Attachment_Scraper\n",
    "\n",
    "from src.database.seedlist_handler import SeedList_Handler\n",
    "\n",
    "from src.database.database_connection import database_connection\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Database\n",
    "Database structure is defined in src/database/database_connection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once. Code creates new Database.\n",
    "con = database_connection()\n",
    "Portal_Scraper(con).init_database_session(create_db=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert Seedlist to Database\n",
    "Seedlist is a .txt document with one URL per line. The URL points to the initatives homepage, like <br> \"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/1362-Access-to-Social-Protection_en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Table named Seedlist and fill with initiative_id and more.\n",
    "con = database_connection()\n",
    "SeedList_Handler(connection=con).insert_seedlist(\"data/seedlist_manual_all_140424_additional-Inis.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Initiatives and Stage Metadata\n",
    "Input are all Initative IDs that, according to seedlist are not scraped yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Scrape all initatives where `initiative_updated` is Null in Seedlist Table\n",
    "2. Upsert initative metadata in Initatives Table\n",
    "3. Upsert stage metadata in Stages Table\n",
    "4. Update 'initiative_updated' in Seedlist with current (GMT) time\n",
    "'''\n",
    "\n",
    "con = database_connection()\n",
    "\n",
    "Initiative_Scraper(connection=con, wait_time=10).scrape_all() # wait_time = time between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display stages in DB by Published Date\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from src.database.database_connection import database_connection\n",
    "\n",
    "engine = create_engine(database_connection(), echo=False, echo_pool=False)\n",
    "\n",
    "stage_dates_published = pd.read_sql(\"SELECT published_date FROM stages\", engine)\n",
    "\n",
    "stage_dates_published = stage_dates_published.value_counts(\"published_date\")\n",
    "stage_dates_published = stage_dates_published.sort_index(ascending=True)\n",
    "\n",
    "stage_dates_published = stage_dates_published.resample('M').agg(\"count\")\n",
    "\n",
    "plt.plot(stage_dates_published.index, stage_dates_published.values)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Feedbacks and Attachment-Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Scrape all Stages where `feedback_updated` is Null in Stages Table\n",
    "2. Upsert feedbacks to Feedbacks Table\n",
    "3. Upsert attachment metadata to Attachments Table\n",
    "4. Update 'feedback_updated' in Stages Table with current time\n",
    "'''\n",
    "\n",
    "con = database_connection()\n",
    "Feedback_Scraper(connection=con, wait_time=10).scrape_all() # wait_time = time between requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Specific Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = database_connection()\n",
    "stage_id_queue = [\n",
    "    31234550, #done\n",
    "    7929317,\n",
    "    26519622, \n",
    "    32232670, \n",
    "    25987338, \n",
    "    32438558]\n",
    "\n",
    "\n",
    "# schufa schicken\n",
    "# pdfs\n",
    "# online treffen\n",
    "# appartment hinhalten bis Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Attachment_Scraper(\u001b[43mcon\u001b[49m, \u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mscrape_all_of_stage(stage_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m31234550\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 090166e5007b5a73 ist ein engescanntes Dokument und lies sich nicht scrapen...\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'con' is not defined"
     ]
    }
   ],
   "source": [
    "con = database_connection()\n",
    "Attachment_Scraper(con, 5).scrape_all_of_stage(stage_id=\"31234550\")\n",
    "\n",
    "# 090166e5007b5a73 ist ein engescanntes Dokument und lies sich nicht scrapen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = database_connection()\n",
    "#Attachment_Scraper(connection=con, wait_time=10, document_id=).scrape_attachments\n",
    "\n",
    "Attachment_Scraper(con, 5).scrape_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hysScraper",
   "language": "python",
   "name": "hysscraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
